// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/open-telemetry/opentelemetry-operator/apis/v1beta1

package v1beta1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	appsv1 "k8s.io/api/apps/v1"
	"k8s.io/api/core/v1"
)

// OpenTelemetryCollector is the Schema for the opentelemetrycollectors API.
#OpenTelemetryCollector: {
	metav1.#TypeMeta
	metadata?: metav1.#ObjectMeta            @go(ObjectMeta)
	spec?:     #OpenTelemetryCollectorSpec   @go(Spec)
	status?:   #OpenTelemetryCollectorStatus @go(Status)
}

// OpenTelemetryCollectorList contains a list of OpenTelemetryCollector.
#OpenTelemetryCollectorList: {
	metav1.#TypeMeta
	metadata?: metav1.#ListMeta @go(ListMeta)
	items: [...#OpenTelemetryCollector] @go(Items,[]OpenTelemetryCollector)
}

// OpenTelemetryCollectorStatus defines the observed state of OpenTelemetryCollector.
#OpenTelemetryCollectorStatus: {
	// Scale is the OpenTelemetryCollector's scale subresource status.
	// +optional
	scale?: #ScaleSubresourceStatus @go(Scale)

	// Version of the managed OpenTelemetry Collector (operand)
	// +optional
	version?: string @go(Version)

	// Image indicates the container image to use for the OpenTelemetry Collector.
	// +optional
	image?: string @go(Image)
}

// OpenTelemetryCollectorSpec defines the desired state of OpenTelemetryCollector.
#OpenTelemetryCollectorSpec: {
	#OpenTelemetryCommonFields

	#StatefulSetCommonFields

	// Autoscaler specifies the pod autoscaling configuration to use
	// for the workload.
	// +optional
	autoscaler?: null | #AutoscalerSpec @go(Autoscaler,*AutoscalerSpec)

	// TargetAllocator indicates a value which determines whether to spawn a target allocation resource or not.
	// +optional
	targetAllocator?: #TargetAllocatorEmbedded @go(TargetAllocator)

	// Mode represents how the collector should be deployed (deployment, daemonset, statefulset or sidecar)
	// +optional
	mode?: #Mode @go(Mode)

	// UpgradeStrategy represents how the operator will handle upgrades to the CR when a newer version of the operator is deployed
	// +optional
	upgradeStrategy?: #UpgradeStrategy @go(UpgradeStrategy)

	// Config is the raw JSON to be used as the collector's configuration. Refer to the OpenTelemetry Collector documentation for details.
	// The empty objects e.g. batch: should be written as batch: {} otherwise they won't work with kustomize or kubectl edit.
	// +required
	// +kubebuilder:pruning:PreserveUnknownFields
	config: #Config @go(Config)

	// ConfigVersions defines the number versions to keep for the collector config. Each config version is stored in a separate ConfigMap.
	// Defaults to 3. The minimum value is 1.
	// +optional
	// +kubebuilder:default:=3
	// +kubebuilder:validation:Minimum:=1
	configVersions?: int @go(ConfigVersions)

	// Ingress is used to specify how OpenTelemetry Collector is exposed. This
	// functionality is only available if one of the valid modes is set.
	// Valid modes are: deployment, daemonset and statefulset.
	// +optional
	ingress?: #Ingress @go(Ingress)

	// Liveness config for the OpenTelemetry Collector except the probe handler which is auto generated from the health extension of the collector.
	// It is only effective when healthcheckextension is configured in the OpenTelemetry Collector pipeline.
	// +optional
	livenessProbe?: null | #Probe @go(LivenessProbe,*Probe)

	// Readiness config for the OpenTelemetry Collector except the probe handler which is auto generated from the health extension of the collector.
	// It is only effective when healthcheckextension is configured in the OpenTelemetry Collector pipeline.
	// +optional
	readinessProbe?: null | #Probe @go(ReadinessProbe,*Probe)

	// ObservabilitySpec defines how telemetry data gets handled.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Observability"
	observability?: #ObservabilitySpec @go(Observability)

	// ConfigMaps is a list of ConfigMaps in the same namespace as the OpenTelemetryCollector
	// object, which shall be mounted into the Collector Pods.
	// Each ConfigMap will be added to the Collector's Deployments as a volume named `configmap-<configmap-name>`.
	configmaps?: [...#ConfigMapsSpec] @go(ConfigMaps,[]ConfigMapsSpec)

	// UpdateStrategy represents the strategy the operator will take replacing existing DaemonSet pods with new pods
	// https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/#DaemonSetSpec
	// This is only applicable to Daemonset mode.
	// +optional
	daemonSetUpdateStrategy?: appsv1.#DaemonSetUpdateStrategy @go(DaemonSetUpdateStrategy)

	// UpdateStrategy represents the strategy the operator will take replacing existing Deployment pods with new pods
	// https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/#DeploymentSpec
	// This is only applicable to Deployment mode.
	// +optional
	deploymentUpdateStrategy?: appsv1.#DeploymentStrategy @go(DeploymentUpdateStrategy)
}

// TargetAllocatorEmbedded defines the configuration for the Prometheus target allocator, embedded in the
// OpenTelemetryCollector spec.
#TargetAllocatorEmbedded: {
	// Replicas is the number of pod instances for the underlying TargetAllocator. This should only be set to a value
	// other than 1 if a strategy that allows for high availability is chosen. Currently, the only allocation strategy
	// that can be run in a high availability mode is consistent-hashing.
	// +optional
	replicas?: null | int32 @go(Replicas,*int32)

	// NodeSelector to schedule OpenTelemetry TargetAllocator pods.
	// +optional
	nodeSelector?: {[string]: string} @go(NodeSelector,map[string]string)

	// Resources to set on the OpenTelemetryTargetAllocator containers.
	// +optional
	resources?: v1.#ResourceRequirements @go(Resources)

	// AllocationStrategy determines which strategy the target allocator should use for allocation.
	// The current options are least-weighted, consistent-hashing and per-node. The default is
	// consistent-hashing.
	// WARNING: The per-node strategy currently ignores targets without a Node, like control plane components.
	// +optional
	// +kubebuilder:default:=consistent-hashing
	allocationStrategy?: #TargetAllocatorAllocationStrategy @go(AllocationStrategy)

	// FilterStrategy determines how to filter targets before allocating them among the collectors.
	// The only current option is relabel-config (drops targets based on prom relabel_config).
	// The default is relabel-config.
	// +optional
	// +kubebuilder:default:=relabel-config
	filterStrategy?: #TargetAllocatorFilterStrategy @go(FilterStrategy)

	// ServiceAccount indicates the name of an existing service account to use with this instance. When set,
	// the operator will not automatically create a ServiceAccount for the TargetAllocator.
	// +optional
	serviceAccount?: string @go(ServiceAccount)

	// Image indicates the container image to use for the OpenTelemetry TargetAllocator.
	// +optional
	image?: string @go(Image)

	// Enabled indicates whether to use a target allocation mechanism for Prometheus targets or not.
	// +optional
	enabled?: bool @go(Enabled)

	// If specified, indicates the pod's scheduling constraints
	// +optional
	affinity?: null | v1.#Affinity @go(Affinity,*v1.Affinity)

	// PrometheusCR defines the configuration for the retrieval of PrometheusOperator CRDs ( servicemonitor.monitoring.coreos.com/v1 and podmonitor.monitoring.coreos.com/v1 )  retrieval.
	// All CR instances which the ServiceAccount has access to will be retrieved. This includes other namespaces.
	// +optional
	prometheusCR?: #TargetAllocatorPrometheusCR @go(PrometheusCR)

	// SecurityContext configures the container security context for
	// the targetallocator.
	// +optional
	securityContext?: null | v1.#SecurityContext @go(SecurityContext,*v1.SecurityContext)

	// PodSecurityContext configures the pod security context for the
	// targetallocator.
	// +optional
	podSecurityContext?: null | v1.#PodSecurityContext @go(PodSecurityContext,*v1.PodSecurityContext)

	// TopologySpreadConstraints embedded kubernetes pod configuration option,
	// controls how pods are spread across your cluster among failure-domains
	// such as regions, zones, nodes, and other user-defined topology domains
	// https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
	// +optional
	topologySpreadConstraints?: [...v1.#TopologySpreadConstraint] @go(TopologySpreadConstraints,[]v1.TopologySpreadConstraint)

	// Toleration embedded kubernetes pod configuration option,
	// controls how pods can be scheduled with matching taints
	// +optional
	tolerations?: [...v1.#Toleration] @go(Tolerations,[]v1.Toleration)

	// ENV vars to set on the OpenTelemetry TargetAllocator's Pods. These can then in certain cases be
	// consumed in the config file for the TargetAllocator.
	// +optional
	env?: [...v1.#EnvVar] @go(Env,[]v1.EnvVar)

	// ObservabilitySpec defines how telemetry data gets handled.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Observability"
	observability?: #ObservabilitySpec @go(Observability)

	// PodDisruptionBudget specifies the pod disruption budget configuration to use
	// for the target allocator workload. By default, a PDB with a MaxUnavailable of one is set for a valid
	// allocation strategy.
	//
	// +optional
	podDisruptionBudget?: null | #PodDisruptionBudgetSpec @go(PodDisruptionBudget,*PodDisruptionBudgetSpec)
}

// Probe defines the OpenTelemetry's pod probe config.
#Probe: {
	// Number of seconds after the container has started before liveness probes are initiated.
	// Defaults to 0 seconds. Minimum value is 0.
	// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
	// +optional
	initialDelaySeconds?: null | int32 @go(InitialDelaySeconds,*int32)

	// Number of seconds after which the probe times out.
	// Defaults to 1 second. Minimum value is 1.
	// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
	// +optional
	timeoutSeconds?: null | int32 @go(TimeoutSeconds,*int32)

	// How often (in seconds) to perform the probe.
	// Default to 10 seconds. Minimum value is 1.
	// +optional
	periodSeconds?: null | int32 @go(PeriodSeconds,*int32)

	// Minimum consecutive successes for the probe to be considered successful after having failed.
	// Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
	// +optional
	successThreshold?: null | int32 @go(SuccessThreshold,*int32)

	// Minimum consecutive failures for the probe to be considered failed after having succeeded.
	// Defaults to 3. Minimum value is 1.
	// +optional
	failureThreshold?: null | int32 @go(FailureThreshold,*int32)

	// Optional duration in seconds the pod needs to terminate gracefully upon probe failure.
	// The grace period is the duration in seconds after the processes running in the pod are sent
	// a termination signal and the time when the processes are forcibly halted with a kill signal.
	// Set this value longer than the expected cleanup time for your process.
	// If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this
	// value overrides the value provided by the pod spec.
	// Value must be non-negative integer. The value zero indicates stop immediately via
	// the kill signal (no opportunity to shut down).
	// This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.
	// Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
	// +optional
	terminationGracePeriodSeconds?: null | int64 @go(TerminationGracePeriodSeconds,*int64)
}

// ObservabilitySpec defines how telemetry data gets handled.
#ObservabilitySpec: {
	// Metrics defines the metrics configuration for operands.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Metrics Config"
	metrics?: #MetricsConfigSpec @go(Metrics)
}

// MetricsConfigSpec defines a metrics config.
#MetricsConfigSpec: {
	// EnableMetrics specifies if ServiceMonitor or PodMonitor(for sidecar mode) should be created for the service managed by the OpenTelemetry Operator.
	// The operator.observability.prometheus feature gate must be enabled to use this feature.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Create ServiceMonitors for OpenTelemetry Collector"
	enableMetrics?: bool @go(EnableMetrics)

	// DisablePrometheusAnnotations controls the automatic addition of default Prometheus annotations
	// ('prometheus.io/scrape', 'prometheus.io/port', and 'prometheus.io/path')
	//
	// +optional
	// +kubebuilder:validation:Optional
	disablePrometheusAnnotations?: bool @go(DisablePrometheusAnnotations)
}

// ScaleSubresourceStatus defines the observed state of the OpenTelemetryCollector's
// scale subresource.
#ScaleSubresourceStatus: {
	// The selector used to match the OpenTelemetryCollector's
	// deployment or statefulSet pods.
	// +optional
	selector?: string @go(Selector)

	// The total number non-terminated pods targeted by this
	// OpenTelemetryCollector's deployment or statefulSet.
	// +optional
	replicas?: int32 @go(Replicas)

	// StatusReplicas is the number of pods targeted by this OpenTelemetryCollector's with a Ready Condition /
	// Total number of non-terminated pods targeted by this OpenTelemetryCollector's (their labels match the selector).
	// Deployment, Daemonset, StatefulSet.
	// +optional
	statusReplicas?: string @go(StatusReplicas)
}

#ConfigMapsSpec: {
	// Configmap defines name and path where the configMaps should be mounted.
	name:      string @go(Name)
	mountpath: string @go(MountPath)
}
