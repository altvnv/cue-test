// Code generated by cue get go. DO NOT EDIT.

//cue:generate cue get go github.com/open-telemetry/opentelemetry-operator/apis/v1alpha1

package v1alpha1

import (
	networkingv1 "k8s.io/api/networking/v1"
	"k8s.io/api/core/v1"
	appsv1 "k8s.io/api/apps/v1"
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	autoscalingv2 "k8s.io/api/autoscaling/v2"
	"k8s.io/apimachinery/pkg/util/intstr"
)

// ManagementStateType defines the type for CR management states.
//
// +kubebuilder:validation:Enum=managed;unmanaged
#ManagementStateType: string // #enumManagementStateType

#enumManagementStateType:
	#ManagementStateManaged |
	#ManagementStateUnmanaged

// ManagementStateManaged when the OpenTelemetryCollector custom resource should be
// reconciled by the operator.
#ManagementStateManaged: #ManagementStateType & "managed"

// ManagementStateUnmanaged when the OpenTelemetryCollector custom resource should not be
// reconciled by the operator.
#ManagementStateUnmanaged: #ManagementStateType & "unmanaged"

// Ingress is used to specify how OpenTelemetry Collector is exposed. This
// functionality is only available if one of the valid modes is set.
// Valid modes are: deployment, daemonset and statefulset.
// NOTE: If this feature is activated, all specified receivers are exposed.
// Currently this has a few limitations. Depending on the ingress controller
// there are problems with TLS and gRPC.
// SEE: https://github.com/open-telemetry/opentelemetry-operator/issues/1306.
// NOTE: As a workaround, port name and appProtocol could be specified directly
// in the CR.
// SEE: OpenTelemetryCollector.spec.ports[index].
#Ingress: {
	// Type default value is: ""
	// Supported types are: ingress, route
	type?: #IngressType @go(Type)

	// RuleType defines how Ingress exposes collector receivers.
	// IngressRuleTypePath ("path") exposes each receiver port on a unique path on single domain defined in Hostname.
	// IngressRuleTypeSubdomain ("subdomain") exposes each receiver port on a unique subdomain of Hostname.
	// Default is IngressRuleTypePath ("path").
	ruleType?: #IngressRuleType @go(RuleType)

	// Hostname by which the ingress proxy can be reached.
	// +optional
	hostname?: string @go(Hostname)

	// Annotations to add to ingress.
	// e.g. 'cert-manager.io/cluster-issuer: "letsencrypt"'
	// +optional
	annotations?: {[string]: string} @go(Annotations,map[string]string)

	// TLS configuration.
	// +optional
	tls?: [...networkingv1.#IngressTLS] @go(TLS,[]networkingv1.IngressTLS)

	// IngressClassName is the name of an IngressClass cluster resource. Ingress
	// controller implementations use this field to know whether they should be
	// serving this Ingress resource.
	// +optional
	ingressClassName?: null | string @go(IngressClassName,*string)

	// Route is an OpenShift specific section that is only considered when
	// type "route" is used.
	// +optional
	route?: #OpenShiftRoute @go(Route)
}

// OpenShiftRoute defines openshift route specific settings.
#OpenShiftRoute: {
	// Termination indicates termination type. By default "edge" is used.
	termination?: #TLSRouteTerminationType @go(Termination)
}

// OpenTelemetryCollectorSpec defines the desired state of OpenTelemetryCollector.
#OpenTelemetryCollectorSpec: {
	// ManagementState defines if the CR should be managed by the operator or not.
	// Default is managed.
	//
	// +required
	// +kubebuilder:validation:Required
	// +kubebuilder:default:=managed
	managementState?: #ManagementStateType @go(ManagementState)

	// Resources to set on the OpenTelemetry Collector pods.
	// +optional
	resources?: v1.#ResourceRequirements @go(Resources)

	// NodeSelector to schedule OpenTelemetry Collector pods.
	// This is only relevant to daemonset, statefulset, and deployment mode
	// +optional
	nodeSelector?: {[string]: string} @go(NodeSelector,map[string]string)

	// Args is the set of arguments to pass to the OpenTelemetry Collector binary
	// +optional
	args?: {[string]: string} @go(Args,map[string]string)

	// Replicas is the number of pod instances for the underlying OpenTelemetry Collector. Set this if your are not using autoscaling
	// +optional
	replicas?: null | int32 @go(Replicas,*int32)

	// MinReplicas sets a lower bound to the autoscaling feature.  Set this if you are using autoscaling. It must be at least 1
	// +optional
	// Deprecated: use "OpenTelemetryCollector.Spec.Autoscaler.MinReplicas" instead.
	minReplicas?: null | int32 @go(MinReplicas,*int32)

	// MaxReplicas sets an upper bound to the autoscaling feature. If MaxReplicas is set autoscaling is enabled.
	// +optional
	// Deprecated: use "OpenTelemetryCollector.Spec.Autoscaler.MaxReplicas" instead.
	maxReplicas?: null | int32 @go(MaxReplicas,*int32)

	// Autoscaler specifies the pod autoscaling configuration to use
	// for the OpenTelemetryCollector workload.
	//
	// +optional
	autoscaler?: null | #AutoscalerSpec @go(Autoscaler,*AutoscalerSpec)

	// PodDisruptionBudget specifies the pod disruption budget configuration to use
	// for the OpenTelemetryCollector workload.
	//
	// +optional
	podDisruptionBudget?: null | #PodDisruptionBudgetSpec @go(PodDisruptionBudget,*PodDisruptionBudgetSpec)

	// SecurityContext configures the container security context for
	// the opentelemetry-collector container.
	//
	// In deployment, daemonset, or statefulset mode, this controls
	// the security context settings for the primary application
	// container.
	//
	// In sidecar mode, this controls the security context for the
	// injected sidecar container.
	//
	// +optional
	securityContext?: null | v1.#SecurityContext @go(SecurityContext,*v1.SecurityContext)

	// PodSecurityContext configures the pod security context for the
	// opentelemetry-collector pod, when running as a deployment, daemonset,
	// or statefulset.
	//
	// In sidecar mode, the opentelemetry-operator will ignore this setting.
	//
	// +optional
	podSecurityContext?: null | v1.#PodSecurityContext @go(PodSecurityContext,*v1.PodSecurityContext)

	// PodAnnotations is the set of annotations that will be attached to
	// Collector and Target Allocator pods.
	// +optional
	podAnnotations?: {[string]: string} @go(PodAnnotations,map[string]string)

	// TargetAllocator indicates a value which determines whether to spawn a target allocation resource or not.
	// +optional
	targetAllocator?: #OpenTelemetryTargetAllocator @go(TargetAllocator)

	// Mode represents how the collector should be deployed (deployment, daemonset, statefulset or sidecar)
	// +optional
	mode?: #Mode @go(Mode)

	// ServiceAccount indicates the name of an existing service account to use with this instance. When set,
	// the operator will not automatically create a ServiceAccount for the collector.
	// +optional
	serviceAccount?: string @go(ServiceAccount)

	// Image indicates the container image to use for the OpenTelemetry Collector.
	// +optional
	image?: string @go(Image)

	// UpgradeStrategy represents how the operator will handle upgrades to the CR when a newer version of the operator is deployed
	// +optional
	upgradeStrategy?: #UpgradeStrategy @go(UpgradeStrategy)

	// ImagePullPolicy indicates the pull policy to be used for retrieving the container image (Always, Never, IfNotPresent)
	// +optional
	imagePullPolicy?: v1.#PullPolicy @go(ImagePullPolicy)

	// Config is the raw YAML to be used as the collector's configuration. Refer to the OpenTelemetry Collector documentation for details.
	// +required
	config?: string @go(Config)

	// VolumeMounts represents the mount points to use in the underlying collector deployment(s)
	// +optional
	// +listType=atomic
	volumeMounts?: [...v1.#VolumeMount] @go(VolumeMounts,[]v1.VolumeMount)

	// Ports allows a set of ports to be exposed by the underlying v1.Service. By default, the operator
	// will attempt to infer the required ports by parsing the .Spec.Config property but this property can be
	// used to open additional ports that can't be inferred by the operator, like for custom receivers.
	// +optional
	// +listType=atomic
	ports?: [...#PortsSpec] @go(Ports,[]PortsSpec)

	// ENV vars to set on the OpenTelemetry Collector's Pods. These can then in certain cases be
	// consumed in the config file for the Collector.
	// +optional
	env?: [...v1.#EnvVar] @go(Env,[]v1.EnvVar)

	// List of sources to populate environment variables on the OpenTelemetry Collector's Pods.
	// These can then in certain cases be consumed in the config file for the Collector.
	// +optional
	envFrom?: [...v1.#EnvFromSource] @go(EnvFrom,[]v1.EnvFromSource)

	// VolumeClaimTemplates will provide stable storage using PersistentVolumes. Only available when the mode=statefulset.
	// +optional
	// +listType=atomic
	volumeClaimTemplates?: [...v1.#PersistentVolumeClaim] @go(VolumeClaimTemplates,[]v1.PersistentVolumeClaim)

	// Toleration to schedule OpenTelemetry Collector pods.
	// This is only relevant to daemonset, statefulset, and deployment mode
	// +optional
	tolerations?: [...v1.#Toleration] @go(Tolerations,[]v1.Toleration)

	// Volumes represents which volumes to use in the underlying collector deployment(s).
	// +optional
	// +listType=atomic
	volumes?: [...v1.#Volume] @go(Volumes,[]v1.Volume)

	// Ingress is used to specify how OpenTelemetry Collector is exposed. This
	// functionality is only available if one of the valid modes is set.
	// Valid modes are: deployment, daemonset and statefulset.
	// +optional
	ingress?: #Ingress @go(Ingress)

	// HostNetwork indicates if the pod should run in the host networking namespace.
	// +optional
	hostNetwork?: bool @go(HostNetwork)

	// ShareProcessNamespace indicates if the pod's containers should share process namespace.
	// +optional
	shareProcessNamespace?: bool @go(ShareProcessNamespace)

	// If specified, indicates the pod's priority.
	// If not specified, the pod priority will be default or zero if there is no
	// default.
	// +optional
	priorityClassName?: string @go(PriorityClassName)

	// If specified, indicates the pod's scheduling constraints
	// +optional
	affinity?: null | v1.#Affinity @go(Affinity,*v1.Affinity)

	// Actions that the management system should take in response to container lifecycle events. Cannot be updated.
	// +optional
	lifecycle?: null | v1.#Lifecycle @go(Lifecycle,*v1.Lifecycle)

	// Duration in seconds the pod needs to terminate gracefully upon probe failure.
	// +optional
	terminationGracePeriodSeconds?: null | int64 @go(TerminationGracePeriodSeconds,*int64)

	// Liveness config for the OpenTelemetry Collector except the probe handler which is auto generated from the health extension of the collector.
	// It is only effective when healthcheckextension is configured in the OpenTelemetry Collector pipeline.
	// +optional
	livenessProbe?: null | #Probe @go(LivenessProbe,*Probe)

	// InitContainers allows injecting initContainers to the Collector's pod definition.
	// These init containers can be used to fetch secrets for injection into the
	// configuration from external sources, run added checks, etc. Any errors during the execution of
	// an initContainer will lead to a restart of the Pod. More info:
	// https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
	// +optional
	initContainers?: [...v1.#Container] @go(InitContainers,[]v1.Container)

	// AdditionalContainers allows injecting additional containers into the Collector's pod definition.
	// These sidecar containers can be used for authentication proxies, log shipping sidecars, agents for shipping
	// metrics to their cloud, or in general sidecars that do not support automatic injection. This option only
	// applies to Deployment, DaemonSet, and StatefulSet deployment modes of the collector. It does not apply to the sidecar
	// deployment mode. More info about sidecars:
	// https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/
	//
	// Container names managed by the operator:
	// * `otc-container`
	//
	// Overriding containers managed by the operator is outside the scope of what the maintainers will support and by
	// doing so, you wil accept the risk of it breaking things.
	//
	// +optional
	additionalContainers?: [...v1.#Container] @go(AdditionalContainers,[]v1.Container)

	// ObservabilitySpec defines how telemetry data gets handled.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Observability"
	observability?: #ObservabilitySpec @go(Observability)

	// TopologySpreadConstraints embedded kubernetes pod configuration option,
	// controls how pods are spread across your cluster among failure-domains
	// such as regions, zones, nodes, and other user-defined topology domains
	// https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
	// This is only relevant to statefulset, and deployment mode
	// +optional
	topologySpreadConstraints?: [...v1.#TopologySpreadConstraint] @go(TopologySpreadConstraints,[]v1.TopologySpreadConstraint)

	// ConfigMaps is a list of ConfigMaps in the same namespace as the OpenTelemetryCollector
	// object, which shall be mounted into the Collector Pods.
	// Each ConfigMap will be added to the Collector's Deployments as a volume named `configmap-<configmap-name>`.
	configmaps?: [...#ConfigMapsSpec] @go(ConfigMaps,[]ConfigMapsSpec)

	// UpdateStrategy represents the strategy the operator will take replacing existing DaemonSet pods with new pods
	// https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/daemon-set-v1/#DaemonSetSpec
	// This is only applicable to Daemonset mode.
	// +optional
	updateStrategy?: appsv1.#DaemonSetUpdateStrategy @go(UpdateStrategy)

	// UpdateStrategy represents the strategy the operator will take replacing existing Deployment pods with new pods
	// https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/deployment-v1/#DeploymentSpec
	// This is only applicable to Deployment mode.
	// +optional
	deploymentUpdateStrategy?: appsv1.#DeploymentStrategy @go(DeploymentUpdateStrategy)
}

// PortsSpec defines the OpenTelemetryCollector's container/service ports additional specifications.
#PortsSpec: {
	// Allows defining which port to bind to the host in the Container.
	// +optional
	hostPort?: int32 @go(HostPort)

	v1.#ServicePort
}

// OpenTelemetryTargetAllocator defines the configurations for the Prometheus target allocator.
#OpenTelemetryTargetAllocator: {
	// Replicas is the number of pod instances for the underlying TargetAllocator. This should only be set to a value
	// other than 1 if a strategy that allows for high availability is chosen. Currently, the only allocation strategy
	// that can be run in a high availability mode is consistent-hashing.
	// +optional
	replicas?: null | int32 @go(Replicas,*int32)

	// NodeSelector to schedule OpenTelemetry TargetAllocator pods.
	// +optional
	nodeSelector?: {[string]: string} @go(NodeSelector,map[string]string)

	// Resources to set on the OpenTelemetryTargetAllocator containers.
	// +optional
	resources?: v1.#ResourceRequirements @go(Resources)

	// AllocationStrategy determines which strategy the target allocator should use for allocation.
	// The current options are least-weighted, consistent-hashing and per-node. The default is
	// consistent-hashing.
	// WARNING: The per-node strategy currently ignores targets without a Node, like control plane components.
	// +optional
	// +kubebuilder:default:=consistent-hashing
	allocationStrategy?: #OpenTelemetryTargetAllocatorAllocationStrategy @go(AllocationStrategy)

	// FilterStrategy determines how to filter targets before allocating them among the collectors.
	// The only current option is relabel-config (drops targets based on prom relabel_config).
	// The default is relabel-config.
	// +optional
	// +kubebuilder:default:=relabel-config
	filterStrategy?: string @go(FilterStrategy)

	// ServiceAccount indicates the name of an existing service account to use with this instance. When set,
	// the operator will not automatically create a ServiceAccount for the TargetAllocator.
	// +optional
	serviceAccount?: string @go(ServiceAccount)

	// Image indicates the container image to use for the OpenTelemetry TargetAllocator.
	// +optional
	image?: string @go(Image)

	// Enabled indicates whether to use a target allocation mechanism for Prometheus targets or not.
	// +optional
	enabled?: bool @go(Enabled)

	// If specified, indicates the pod's scheduling constraints
	// +optional
	affinity?: null | v1.#Affinity @go(Affinity,*v1.Affinity)

	// PrometheusCR defines the configuration for the retrieval of PrometheusOperator CRDs ( servicemonitor.monitoring.coreos.com/v1 and podmonitor.monitoring.coreos.com/v1 )  retrieval.
	// All CR instances which the ServiceAccount has access to will be retrieved. This includes other namespaces.
	// +optional
	prometheusCR?: #OpenTelemetryTargetAllocatorPrometheusCR @go(PrometheusCR)

	// SecurityContext configures the container security context for
	// the targetallocator.
	// +optional
	securityContext?: null | v1.#SecurityContext @go(SecurityContext,*v1.SecurityContext)

	// PodSecurityContext configures the pod security context for the
	// targetallocator.
	// +optional
	podSecurityContext?: null | v1.#PodSecurityContext @go(PodSecurityContext,*v1.PodSecurityContext)

	// TopologySpreadConstraints embedded kubernetes pod configuration option,
	// controls how pods are spread across your cluster among failure-domains
	// such as regions, zones, nodes, and other user-defined topology domains
	// https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
	// +optional
	topologySpreadConstraints?: [...v1.#TopologySpreadConstraint] @go(TopologySpreadConstraints,[]v1.TopologySpreadConstraint)

	// Toleration embedded kubernetes pod configuration option,
	// controls how pods can be scheduled with matching taints
	// +optional
	tolerations?: [...v1.#Toleration] @go(Tolerations,[]v1.Toleration)

	// ENV vars to set on the OpenTelemetry TargetAllocator's Pods. These can then in certain cases be
	// consumed in the config file for the TargetAllocator.
	// +optional
	env?: [...v1.#EnvVar] @go(Env,[]v1.EnvVar)

	// ObservabilitySpec defines how telemetry data gets handled.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Observability"
	observability?: #ObservabilitySpec @go(Observability)

	// PodDisruptionBudget specifies the pod disruption budget configuration to use
	// for the target allocator workload.
	//
	// +optional
	podDisruptionBudget?: null | #PodDisruptionBudgetSpec @go(PodDisruptionBudget,*PodDisruptionBudgetSpec)
}

#OpenTelemetryTargetAllocatorPrometheusCR: {
	// Enabled indicates whether to use a PrometheusOperator custom resources as targets or not.
	// +optional
	enabled?: bool @go(Enabled)

	// Interval between consecutive scrapes. Equivalent to the same setting on the Prometheus CRD.
	//
	// Default: "30s"
	// +kubebuilder:default:="30s"
	// +kubebuilder:validation:Format:=duration
	scrapeInterval?: null | metav1.#Duration @go(ScrapeInterval,*metav1.Duration)

	// PodMonitors to be selected for target discovery.
	// This is a map of {key,value} pairs. Each {key,value} in the map is going to exactly match a label in a
	// PodMonitor's meta labels. The requirements are ANDed.
	// Empty or nil map matches all pod monitors.
	// +optional
	podMonitorSelector?: {[string]: string} @go(PodMonitorSelector,map[string]string)

	// ServiceMonitors to be selected for target discovery.
	// This is a map of {key,value} pairs. Each {key,value} in the map is going to exactly match a label in a
	// ServiceMonitor's meta labels. The requirements are ANDed.
	// Empty or nil map matches all service monitors.
	// +optional
	serviceMonitorSelector?: {[string]: string} @go(ServiceMonitorSelector,map[string]string)
}

// ScaleSubresourceStatus defines the observed state of the OpenTelemetryCollector's
// scale subresource.
#ScaleSubresourceStatus: {
	// The selector used to match the OpenTelemetryCollector's
	// deployment or statefulSet pods.
	// +optional
	selector?: string @go(Selector)

	// The total number non-terminated pods targeted by this
	// OpenTelemetryCollector's deployment or statefulSet.
	// +optional
	replicas?: int32 @go(Replicas)

	// StatusReplicas is the number of pods targeted by this OpenTelemetryCollector's with a Ready Condition /
	// Total number of non-terminated pods targeted by this OpenTelemetryCollector's (their labels match the selector).
	// Deployment, Daemonset, StatefulSet.
	// +optional
	statusReplicas?: string @go(StatusReplicas)
}

// OpenTelemetryCollectorStatus defines the observed state of OpenTelemetryCollector.
#OpenTelemetryCollectorStatus: {
	// Scale is the OpenTelemetryCollector's scale subresource status.
	// +optional
	scale?: #ScaleSubresourceStatus @go(Scale)

	// Version of the managed OpenTelemetry Collector (operand)
	// +optional
	version?: string @go(Version)

	// Image indicates the container image to use for the OpenTelemetry Collector.
	// +optional
	image?: string @go(Image)

	// Messages about actions performed by the operator on this resource.
	// +optional
	// +listType=atomic
	// Deprecated: use Kubernetes events instead.
	messages?: [...string] @go(Messages,[]string)

	// Replicas is currently not being set and might be removed in the next version.
	// +optional
	// Deprecated: use "OpenTelemetryCollector.Status.Scale.Replicas" instead.
	replicas?: int32 @go(Replicas)
}

// OpenTelemetryCollector is the Schema for the opentelemetrycollectors API.
#OpenTelemetryCollector: {
	metav1.#TypeMeta
	metadata?: metav1.#ObjectMeta            @go(ObjectMeta)
	spec?:     #OpenTelemetryCollectorSpec   @go(Spec)
	status?:   #OpenTelemetryCollectorStatus @go(Status)
}

// OpenTelemetryCollectorList contains a list of OpenTelemetryCollector.
#OpenTelemetryCollectorList: {
	metav1.#TypeMeta
	metadata?: metav1.#ListMeta @go(ListMeta)
	items: [...#OpenTelemetryCollector] @go(Items,[]OpenTelemetryCollector)
}

// AutoscalerSpec defines the OpenTelemetryCollector's pod autoscaling specification.
#AutoscalerSpec: {
	// MinReplicas sets a lower bound to the autoscaling feature.  Set this if your are using autoscaling. It must be at least 1
	// +optional
	minReplicas?: null | int32 @go(MinReplicas,*int32)

	// MaxReplicas sets an upper bound to the autoscaling feature. If MaxReplicas is set autoscaling is enabled.
	// +optional
	maxReplicas?: null | int32 @go(MaxReplicas,*int32)

	// +optional
	behavior?: null | autoscalingv2.#HorizontalPodAutoscalerBehavior @go(Behavior,*autoscalingv2.HorizontalPodAutoscalerBehavior)

	// Metrics is meant to provide a customizable way to configure HPA metrics.
	// currently the only supported custom metrics is type=Pod.
	// Use TargetCPUUtilization or TargetMemoryUtilization instead if scaling on these common resource metrics.
	// +optional
	metrics?: [...#MetricSpec] @go(Metrics,[]MetricSpec)

	// TargetCPUUtilization sets the target average CPU used across all replicas.
	// If average CPU exceeds this value, the HPA will scale up. Defaults to 90 percent.
	// +optional
	targetCPUUtilization?: null | int32 @go(TargetCPUUtilization,*int32)

	// +optional
	// TargetMemoryUtilization sets the target average memory utilization across all replicas
	targetMemoryUtilization?: null | int32 @go(TargetMemoryUtilization,*int32)
}

// PodDisruptionBudgetSpec defines the OpenTelemetryCollector's pod disruption budget specification.
#PodDisruptionBudgetSpec: {
	// An eviction is allowed if at least "minAvailable" pods selected by
	// "selector" will still be available after the eviction, i.e. even in the
	// absence of the evicted pod.  So for example you can prevent all voluntary
	// evictions by specifying "100%".
	// +optional
	minAvailable?: null | intstr.#IntOrString @go(MinAvailable,*intstr.IntOrString)

	// An eviction is allowed if at most "maxUnavailable" pods selected by
	// "selector" are unavailable after the eviction, i.e. even in absence of
	// the evicted pod. For example, one can prevent all voluntary evictions
	// by specifying 0. This is a mutually exclusive setting with "minAvailable".
	// +optional
	maxUnavailable?: null | intstr.#IntOrString @go(MaxUnavailable,*intstr.IntOrString)
}

// MetricsConfigSpec defines a metrics config.
#MetricsConfigSpec: {
	// EnableMetrics specifies if ServiceMonitor or PodMonitor(for sidecar mode) should be created for the service managed by the OpenTelemetry Operator.
	// The operator.observability.prometheus feature gate must be enabled to use this feature.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Create ServiceMonitors for OpenTelemetry Collector"
	enableMetrics?: bool @go(EnableMetrics)

	// DisablePrometheusAnnotations controls the automatic addition of default Prometheus annotations
	// ('prometheus.io/scrape', 'prometheus.io/port', and 'prometheus.io/path')
	//
	// +optional
	// +kubebuilder:validation:Optional
	DisablePrometheusAnnotations?: bool
}

// ObservabilitySpec defines how telemetry data gets handled.
#ObservabilitySpec: {
	// Metrics defines the metrics configuration for operands.
	//
	// +optional
	// +kubebuilder:validation:Optional
	// +operator-sdk:csv:customresourcedefinitions:type=spec,displayName="Metrics Config"
	metrics?: #MetricsConfigSpec @go(Metrics)
}

// Probe defines the OpenTelemetry's pod probe config. Only Liveness probe is supported currently.
#Probe: {
	// Number of seconds after the container has started before liveness probes are initiated.
	// Defaults to 0 seconds. Minimum value is 0.
	// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
	// +optional
	initialDelaySeconds?: null | int32 @go(InitialDelaySeconds,*int32)

	// Number of seconds after which the probe times out.
	// Defaults to 1 second. Minimum value is 1.
	// More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
	// +optional
	timeoutSeconds?: null | int32 @go(TimeoutSeconds,*int32)

	// How often (in seconds) to perform the probe.
	// Default to 10 seconds. Minimum value is 1.
	// +optional
	periodSeconds?: null | int32 @go(PeriodSeconds,*int32)

	// Minimum consecutive successes for the probe to be considered successful after having failed.
	// Defaults to 1. Must be 1 for liveness and startup. Minimum value is 1.
	// +optional
	successThreshold?: null | int32 @go(SuccessThreshold,*int32)

	// Minimum consecutive failures for the probe to be considered failed after having succeeded.
	// Defaults to 3. Minimum value is 1.
	// +optional
	failureThreshold?: null | int32 @go(FailureThreshold,*int32)

	// Optional duration in seconds the pod needs to terminate gracefully upon probe failure.
	// The grace period is the duration in seconds after the processes running in the pod are sent
	// a termination signal and the time when the processes are forcibly halted with a kill signal.
	// Set this value longer than the expected cleanup time for your process.
	// If this value is nil, the pod's terminationGracePeriodSeconds will be used. Otherwise, this
	// value overrides the value provided by the pod spec.
	// Value must be non-negative integer. The value zero indicates stop immediately via
	// the kill signal (no opportunity to shut down).
	// This is a beta field and requires enabling ProbeTerminationGracePeriod feature gate.
	// Minimum value is 1. spec.terminationGracePeriodSeconds is used if unset.
	// +optional
	terminationGracePeriodSeconds?: null | int64 @go(TerminationGracePeriodSeconds,*int64)
}

// MetricSpec defines a subset of metrics to be defined for the HPA's metric array
// more metric type can be supported as needed.
// See https://pkg.go.dev/k8s.io/api/autoscaling/v2#MetricSpec for reference.
#MetricSpec: {
	type:  autoscalingv2.#MetricSourceType        @go(Type)
	pods?: null | autoscalingv2.#PodsMetricSource @go(Pods,*autoscalingv2.PodsMetricSource)
}

#ConfigMapsSpec: {
	// Configmap defines name and path where the configMaps should be mounted.
	name:      string @go(Name)
	mountpath: string @go(MountPath)
}
